{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaZN+rkcLh9gwLNxtoScHx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-multiflow"
      ],
      "metadata": {
        "id": "3YNvCiyM1J6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.float = np\n",
        "np.int = np"
      ],
      "metadata": {
        "id": "jZp49akG1g_Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from skmultiflow.data import SEAGenerator\n",
        "from skmultiflow.meta import AccuracyWeightedEnsembleClassifier as AWE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "window_size = 1000\n",
        "max_iterations = 10\n",
        "\n",
        "stream = SEAGenerator()\n",
        "\n",
        "pre_train_size = 100\n",
        "X_pre_train, y_pre_train = stream.next_sample(pre_train_size)\n",
        "\n",
        "model = AWE()\n",
        "model.fit(X_pre_train, y_pre_train)\n",
        "\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "\n",
        "# Janela deslizante com avaliação prequential\n",
        "for i in range(max_iterations):\n",
        "    X_batch, y_batch = stream.next_sample(window_size)  # new batch\n",
        "    model.fit(X_batch, y_batch)\n",
        "\n",
        "    X_validation, y_validation = stream.next_sample(window_size)\n",
        "    y_pred = model.predict(X_validation)\n",
        "\n",
        "    accuracy = accuracy_score(y_validation, y_pred)\n",
        "    precision = precision_score(y_validation, y_pred, average='weighted')\n",
        "    recall = recall_score(y_validation, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_validation, y_pred, average='weighted')\n",
        "\n",
        "    accuracy_list.append(accuracy if not np.isnan(accuracy) else 0)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    print(f\"Iteração {i+1}/{max_iterations}\")\n",
        "    print(f\"Métricas acumuladas até agora: {accuracy_list}\")\n",
        "\n",
        "# Calcular as médias das métricas\n",
        "mean_accuracy = np.mean(accuracy_list)\n",
        "mean_precision = np.mean(precision_list)\n",
        "mean_recall = np.mean(recall_list)\n",
        "mean_f1 = np.mean(f1_list)\n",
        "\n",
        "# Exibir os resultados\n",
        "print(\"Médias das Métricas de Avaliação:\")\n",
        "print(f\"Acurácia: {mean_accuracy}\")\n",
        "print(f\"Precisão: {mean_precision}\")\n",
        "print(f\"Recall: {mean_recall}\")\n",
        "print(f\"F1-Score: {mean_f1}\")\n"
      ],
      "metadata": {
        "id": "yWb88UXSDcdU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}